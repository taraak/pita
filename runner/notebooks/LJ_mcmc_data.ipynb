{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchsde\n",
    "from src.energies.base_prior import MeanFreePrior, Prior\n",
    "from src.energies.gmm_energy import GMM, GMMTempWrapper\n",
    "from src.models.components.clipper import Clipper\n",
    "from src.models.components.mlp import MyMLP, MyMLPTemperature\n",
    "from src.utils.data_utils import remove_mean\n",
    "from torch import vmap\n",
    "from torch.func import hessian\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchdiffeq import odeint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from fab.target_distributions import gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "noise_std = 0.2\n",
    "\n",
    "samples = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 13\n",
    "spatial_dim = 3\n",
    "dimensionality = spatial_dim * n_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.5, 2.0, 3.0, 4.0]\n",
    "for i in range(1, 121):\n",
    "    temp_idx = (i - 1) // 10\n",
    "    temp = temps[temp_idx]\n",
    "    path_pattern = f\"/network/scratch/a/alexander.tong/lj13_samples/samples_v22_{i}.npy\"\n",
    "\n",
    "    # try catch permission error\n",
    "\n",
    "    files = sorted(glob.glob(path_pattern))\n",
    "    # print(f\"Found {len(files)} files for temperature {temp}\")\n",
    "    arrays = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            arrays.append(np.load(file))\n",
    "        except PermissionError:\n",
    "            print(f\"Permission error for file {file}\")\n",
    "            break\n",
    "\n",
    "    s = np.concatenate(arrays, axis=0)\n",
    "    s = s.reshape(-1, dimensionality)\n",
    "    samples[temp].append(s)\n",
    "\n",
    "for temp in temps:\n",
    "    print(temp)\n",
    "    if len(samples[temp]) == 0:\n",
    "        continue\n",
    "    samples[temp] = np.concatenate(samples[temp], axis=0)\n",
    "    print(f\"Samples at {temp} has shape: {samples[temp].shape}\")\n",
    "\n",
    "    idxs = np.random.permutation(samples[temp].shape[0])\n",
    "    train_idx = idxs[:10000]\n",
    "    val_idx = idxs[10000:20000]\n",
    "    test_idx = idxs[20000:30000]\n",
    "\n",
    "    samples_train = samples[temp][train_idx]\n",
    "    samples_val = samples[temp][val_idx]\n",
    "    samples_test = samples[temp][test_idx]\n",
    "\n",
    "    # if directory does not exist, create it\n",
    "    import os\n",
    "\n",
    "    temp = temp.__float__()\n",
    "    data_path = f\"../../data/LJ13_temp_{temp}\"\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    else:\n",
    "        print(f\"Directory {data_path} already exists. Overwriting data.\")\n",
    "\n",
    "    np.save(data_path + f\"/train_split_LJ13-1000.npy\", samples_train)\n",
    "    np.save(data_path + f\"/val_split_LJ13-1000.npy\", samples_val)\n",
    "    np.save(data_path + f\"/test_split_LJ13-1000.npy\", samples_test)\n",
    "    print(f\"Saved data for temperature {temp} to {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.5, 2.0, 3.0, 4.0]\n",
    "for temp in temps:\n",
    "    path_pattern = f\"/network/scratch/a/alexander.tong/lj13_samples/samples_v23_{temp}*\"\n",
    "    # try catch permission error\n",
    "\n",
    "    files = sorted(glob.glob(path_pattern))\n",
    "    print(f\"Found {len(files)} files for temperature {temp}\")\n",
    "    arrays = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            arrays.append(np.load(file))\n",
    "        except PermissionError:\n",
    "            print(f\"Permission error for file {file}\")\n",
    "            break\n",
    "    if len(arrays) == 0:\n",
    "        print(f\"No files found for temperature {temp}\")\n",
    "        continue\n",
    "\n",
    "    samples = np.concatenate(arrays)\n",
    "    print(f\"Concatenated array shape: {samples.shape}\")\n",
    "    samples = samples.reshape(-1, dimensionality)\n",
    "\n",
    "    idxs = np.random.permutation(samples.shape[0])\n",
    "    train_idx = idxs[:10000]\n",
    "    val_idx = idxs[10000:20000]\n",
    "    test_idx = idxs[20000:30000]\n",
    "\n",
    "    samples_train = samples[train_idx]\n",
    "    samples_val = samples[val_idx]\n",
    "    samples_test = samples[test_idx]\n",
    "\n",
    "    # if directory does not exist, create it\n",
    "    import os\n",
    "\n",
    "    temp = temp.__float__()\n",
    "    data_path = f\"../../data/LJ13_temp_{temp}\"\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    else:\n",
    "        print(f\"Directory {data_path} already exists. Overwriting data.\")\n",
    "\n",
    "    np.save(data_path + f\"/train_split_LJ13-1000.npy\", samples_train)\n",
    "    np.save(data_path + f\"/val_split_LJ13-1000.npy\", samples_val)\n",
    "    np.save(data_path + f\"/test_split_LJ13-1000.npy\", samples_test)\n",
    "    print(f\"Saved data for temperature {temp} to {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
