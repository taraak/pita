{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.energies.alp_energy import ALPEnergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "Samples at 1200 has shape: (100000, 129)\n",
      "Directory ../../data/alanine/AL43_temp_1200.0 already exists. Overwriting data.\n",
      "Saved data for temperature 1200.0 to ../../data/alanine/AL43_temp_1200.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n_particles = 43 #33 #22\n",
    "n_spatial_dim = 3\n",
    "dimensionality = n_spatial_dim * n_particles\n",
    "\n",
    "samples = defaultdict(list)\n",
    "\n",
    "\n",
    "# NOTE: for the highest temperature (1200), we actually want to take the firt part of the MD traj as train set and not randomly split\n",
    "temps = [1200]\n",
    "for temp in temps:\n",
    "    print(temp)\n",
    "    # path = f\"/network/scratch/a/alexander.tong/energy_temp/data/md/A_capped/A_capped_{temp}_100000/\"\n",
    "    # path = f\"/network/scratch/a/alexander.tong/energy_temp/data/md/AAA/AAA_{temp}_100000/\"\n",
    "    path = f\"/network/scratch/a/alexander.tong/energy_temp/data/md/AAAA/AAAA_{temp}_100000/\"\n",
    "\n",
    "\n",
    "    files = glob.glob(path + \"*.npz\")\n",
    "    try:\n",
    "        # load all files in the directory\n",
    "        samples = np.concatenate([np.load(file)[\"all_positions\"] for file in files])\n",
    "        # samples = np.load(path)\n",
    "        # samples = samples[\"all_positions\"]\n",
    "        samples = samples.reshape(-1, dimensionality)\n",
    "        print(f\"Samples at {temp} has shape: {samples.shape}\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission error for file {path}\")\n",
    "        break\n",
    "\n",
    "    samples_train = samples[:50000]\n",
    "    idxs = np.random.permutation(samples_train.shape[0])\n",
    "    val_idx = idxs[:10000]\n",
    "    samples_val = samples[val_idx]\n",
    "\n",
    "\n",
    "    remaining_samples = samples[50000:]\n",
    "    idxs = np.random.permutation(remaining_samples.shape[0])\n",
    "    test_idx = idxs[:1000]    \n",
    "    samples_test = remaining_samples[test_idx]\n",
    "\n",
    "\n",
    "    # if directory does not exist, create it\n",
    "    import os\n",
    "\n",
    "    temp = temp.__float__()\n",
    "    data_path = f\"../../data/alanine/AL{n_particles}_temp_{temp}\"\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    else:\n",
    "        print(f\"Directory {data_path} already exists. Overwriting data.\")\n",
    "\n",
    "    np.save(data_path + f\"/train_split_AL{n_particles}-10000.npy\", samples_train)\n",
    "    np.save(data_path + f\"/val_split_AL{n_particles}-10000.npy\", samples_val)\n",
    "    np.save(data_path + f\"/test_split_AL{n_particles}-10000.npy\", samples_test)\n",
    "    print(f\"Saved data for temperature {temp} to {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "Samples at 1200 has shape: (100000, 129)\n",
      "Saved data for temperature 1200.0 to ../../data/alanine/AL43_temp_1200.0\n",
      "1028.69\n",
      "Samples at 1028.69 has shape: (100000, 129)\n",
      "Saved data for temperature 1028.69 to ../../data/alanine/AL43_temp_1028.69\n",
      "881.84\n",
      "Samples at 881.84 has shape: (100000, 129)\n",
      "Saved data for temperature 881.84 to ../../data/alanine/AL43_temp_881.84\n",
      "755.95\n",
      "Samples at 755.95 has shape: (100000, 129)\n",
      "Saved data for temperature 755.95 to ../../data/alanine/AL43_temp_755.95\n",
      "648.04\n",
      "Samples at 648.04 has shape: (100000, 129)\n",
      "Saved data for temperature 648.04 to ../../data/alanine/AL43_temp_648.04\n",
      "555.52\n",
      "Samples at 555.52 has shape: (100000, 129)\n",
      "Saved data for temperature 555.52 to ../../data/alanine/AL43_temp_555.52\n",
      "476.22\n",
      "Samples at 476.22 has shape: (100000, 129)\n",
      "Saved data for temperature 476.22 to ../../data/alanine/AL43_temp_476.22\n",
      "408.24\n",
      "Samples at 408.24 has shape: (100000, 129)\n",
      "Saved data for temperature 408.24 to ../../data/alanine/AL43_temp_408.24\n",
      "349.96\n",
      "Samples at 349.96 has shape: (52000, 129)\n",
      "Saved data for temperature 349.96 to ../../data/alanine/AL43_temp_349.96\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n_particles = 22 #33 #22\n",
    "n_spatial_dim = 3\n",
    "dimensionality = n_spatial_dim * n_particles\n",
    "\n",
    "samples = defaultdict(list)\n",
    "\n",
    "# temps = [300, 400, 450, 500, 550, 600]\n",
    "# temps = [1028.69, 881.84, 755.95, 648.04, 555.52, 476.22, 408.24, 349.96]\n",
    "for temp in temps:\n",
    "    print(temp)\n",
    "    path = f\"/network/scratch/a/alexander.tong/energy_temp/data/md/A_capped/A_capped_{temp}_100000/\"\n",
    "    # path = f\"/network/scratch/a/alexander.tong/energy_temp/data/md/AAA/AAA_{temp}_100000/\"\n",
    "    # path = f\"/network/scratch/a/alexander.tong/energy_temp/data/md/AAAA/AAAA_{temp}_100000/\"\n",
    "    # get all files in the directory\n",
    "    files = glob.glob(path + \"*.npz\")\n",
    "\n",
    "    try:\n",
    "        # load all files in the directory\n",
    "        samples = np.concatenate([np.load(file)[\"all_positions\"] for file in files])\n",
    "        # samples = np.load(path)\n",
    "        # samples = samples[\"all_positions\"]\n",
    "        samples = samples.reshape(-1, dimensionality)\n",
    "        print(f\"Samples at {temp} has shape: {samples.shape}\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission error for file {path}\")\n",
    "        break\n",
    "\n",
    "    idxs = np.random.permutation(samples.shape[0])\n",
    "    train_idx = idxs[:10000]\n",
    "    val_idx = idxs[10000:20000]\n",
    "    test_idx = idxs[20000:30000]\n",
    "\n",
    "    samples_train = samples[train_idx]\n",
    "    samples_val = samples[val_idx]\n",
    "    samples_test = samples[test_idx]\n",
    "\n",
    "    # print(f\"Train samples shape: {samples_train.shape}\")\n",
    "    # print(f\"Val samples shape: {samples_val.shape}\")\n",
    "    # print(f\"Test samples shape: {samples_test.shape}\")\n",
    "    # break\n",
    "\n",
    "    # if directory does not exist, create it\n",
    "    import os\n",
    "\n",
    "    temp = temp.__float__()\n",
    "    data_path = f\"../../data/alanine/AL{n_particles}_temp_{temp}\"\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    else:\n",
    "        print(f\"Directory {data_path} already exists. Overwriting data.\")\n",
    "\n",
    "    np.save(data_path + f\"/train_split_AL{n_particles}-10000.npy\", samples_train)\n",
    "    np.save(data_path + f\"/val_split_AL{n_particles}-10000.npy\", samples_val)\n",
    "    np.save(data_path + f\"/test_split_AL{n_particles}-10000.npy\", samples_test)\n",
    "    print(f\"Saved data for temperature {temp} to {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Standard Deviations for normalization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 43\n",
    "n_spatial_dim = 3\n",
    "dimensionality = n_spatial_dim * n_particles\n",
    "\n",
    "\n",
    "if n_particles == 22:\n",
    "    pdb_path = \"../../data/pdbs/AA_capped.pdb\"\n",
    "elif n_particles == 33:\n",
    "    pdb_path = \"../../data/pdbs/AAA.pdb\"\n",
    "elif n_particles == 43:\n",
    "    pdb_path = \"../../data/pdbs/AAAA.pdb\"\n",
    "\n",
    "\n",
    "energy = ALPEnergy(\n",
    "    data_path=\"../../data/alanine/\",\n",
    "    pdb_filename=pdb_path,\n",
    "    n_particles=n_particles,\n",
    "    spatial_dim=n_spatial_dim,\n",
    "    dimensionality=dimensionality,\n",
    "    temperature=1200,\n",
    "    device=device,\n",
    "    device_index=\"0\",\n",
    "    should_normalize=True,\n",
    "    data_normalization_factor=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2446, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = energy.sample_train_set(50000).reshape(-1, n_particles, n_spatial_dim)\n",
    "\n",
    "train_set.std((0, 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
