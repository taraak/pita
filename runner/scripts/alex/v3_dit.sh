RUN_NAME="bigdit"
HYDRA_FULL_ERROR=1 python src/train.py +trainer.num_sanity_val_steps=0 \
model=energytemp \
experiment=alp_energytemp \
trainer=ddp model.resampling_interval=1 \
tags=["test","ALDP","big"] \
model.noise_schedule.sigma_min=0.005 \
trainer.check_val_every_n_epoch=2 \
trainer.max_epochs=6 \
model.dem.num_training_epochs=0 \
model.debias_inference=False \
model.loss_weights.energy_matching=0.0 \
model.do_energy_matching_loss_every_n_steps=1 \
model.loss_weights.energy_score=0.0 \
model.loss_weights.score=1.0 \
model.loss_weights.target_score=0.0 \
model.inference_batch_size=512 \
model.num_samples_to_save=4096 \
model.num_negative_time_steps=0 \
model/net=dit \
model.end_resampling_step=800 \
++model.compile=True \
model.net.hidden_size=768 \
model.net.cond_dim=64 \
model.net.n_blocks=6 \
model.net.n_heads=6 \
hydra.run.dir='${paths.log_dir}/${task_name}/runs/'${RUN_NAME} \
ckpt_path='${paths.log_dir}/${task_name}/runs/'${RUN_NAME}/checkpoints/last.ckpt \
logger.wandb.id=${RUN_NAME}
#model.num_samples_to_save=5000 \
#debug=short \
#model/net=egnn_dynamics_ad2_cat \
#++model.debug_fm=True \
#model.inference_batch_size=384 \
#model.net.hidden_nf=64 \
#model.net.n_layers=5 \
#model/net=dit \
#model.end_resampling_step=900 \
#model.net.hidden_nf=64 \
#model/net=egnn_dynamics_ad2_cat \
#++model.compile=True
#trainer.gradient_clip_val=100 \
#model.do_langevin=true \
#debug=short \
#+model.only_train_score=True \
#+energy.debug_train_on_test=True \
