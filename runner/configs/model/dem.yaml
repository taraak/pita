_target_: src.models.dem_module.DEMLitModule

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10

defaults:
  - net:
    - mlp
    
cfm_net:
  _target_: src.models.components.mlp.MyMLP
  hidden_size: 128
  hidden_layers: 3
  emb_size: 128
  time_emb: "sinusoidal"
  input_emb: "sinusoidal"

noise_schedule:
  _target_: src.models.components.noise_schedules.GeometricNoiseSchedule
  sigma_min: 4e-6
  sigma_max: 0.4

partial_prior:
  _target_: src.energies.base_prior.Prior
  _partial_: true
  dim: 2

buffer:
  _target_: src.models.components.prioritised_replay_buffer.SimpleBuffer
  dim: ${energy.dimensionality}
  max_length: 10000
  min_sample_length: 1000
  initial_sampler: null
  device: ${trainer.accelerator}
  sample_with_replacement: True
  fill_buffer_during_init: False
  prioritize: False #True

clipper:
  _target_: src.models.components.clipper.Clipper
  should_clip_scores: True
  should_clip_log_rewards: False
  max_score_norm: 50
  min_log_reward: null

lambda_weighter:
  _target_: src.models.components.lambda_weighter.BasicLambdaWeighter
  _partial_: true
  epsilon: 1e-3

score_scaler: null

num_init_samples: 1024
num_estimator_mc_samples: 100
num_samples_to_generate_per_epoch: 1024
num_samples_to_sample_from_buffer: 5120
num_integration_steps: 1000

diffusion_scale: 1.0

lr_scheduler_update_frequency: ${trainer.check_val_every_n_epoch}

input_scaling_factor: null
output_scaling_factor: null

compute_nll: False

# compile model for faster training with pytorch 2.0
compile: false

