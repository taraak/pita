# @package _global_

# to execute this experiment run:
# python train.py experiment=example

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["LJ13"]

seed: 12345

logger:
  wandb:
    tags: ${tags}
    group: "lj13"

defaults:
  - override /energy: lj13
  - override /model/net: egnn_temp
  - override /model/noise_schedule: elucidating


model:
  net:
    n_layers: 5
    hidden_nf: 128

  partial_prior:
    _target_: src.energies.base_prior.MeanFreePrior
    _partial_: true
    n_particles: 13
    spatial_dim: 3

  lambda_weighter:
    _target_: src.models.components.lambda_weighter.NoLambdaWeighter
    _partial_: true

  clipper:
    _target_: src.models.components.clipper.Clipper
    should_clip_scores: True
    should_clip_log_rewards: False
    max_score_norm: 1000
    min_log_reward: null

  diffusion_scale: 1.0
  num_negative_time_steps: 1
  num_samples_to_generate_per_epoch: 512
  num_samples_to_sample_from_buffer: 512

  init_from_prior: true

  cfm_prior_std: 2
  nll_integration_method: dopri5
  logz_with_cfm: false
  nll_with_cfm: false

  num_integration_steps: 100

  num_samples_to_save: 10240

  # energytemp parameters
  test_batch_size: 10000
  num_eval_samples: 128
  inference_batch_size: 128
  resampling_interval: 1
  start_resampling_step: 10
  scale_diffusion: False

  lower_temperature: 1.5
  higher_temperature: 2.0
  d_temp: 0.5
  
