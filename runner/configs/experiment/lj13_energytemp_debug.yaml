# @package _global_

# to execute this experiment run:
# python train.py experiment=example

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["LJ13"]

seed: 12345

logger:
  wandb:
    tags: ${tags}
    group: "lj13"

defaults:
  - override /energy: lj13
  - override /model/net: egnn_temp
  - override /model/noise_schedule: elucidating


model:
  partial_prior:
    _target_: src.energies.base_prior.MeanFreePrior
    _partial_: true
    n_particles: 13
    spatial_dim: 3

  lambda_weighter:
    _target_: src.models.components.lambda_weighter.NoLambdaWeighter
    _partial_: true

  clipper:
    _target_: src.models.components.clipper.Clipper
    should_clip_scores: True
    should_clip_log_rewards: False
    max_score_norm: 1000
    min_log_reward: null

  diffusion_scale: 1.0
  num_negative_time_steps: 0
  num_samples_to_generate_per_epoch: 1024
  num_samples_to_sample_from_buffer: 512

  cfm_prior_std: 2
  nll_integration_method: dopri5
  logz_with_cfm: false
  nll_with_cfm: false

  num_samples_to_save: 10000
  num_integration_steps: 1000


  # Elucidating noise schedule
  P_mean: -1.2
  P_std: 1.2

  # energytemp parameters
  num_init_samples: 10000
  test_batch_size: 5000
  num_eval_samples: 128
  inference_batch_size: 512 
  resampling_interval: 1
  start_resampling_step: 10
  scale_diffusion: False

  lower_temperature: 1.0
  higher_temperature: 2.0
  d_temp: 0.1

  temperatures: 
    - 2.0
  
  init_from_prior: false
