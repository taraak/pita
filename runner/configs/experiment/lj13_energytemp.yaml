# @package _global_

# to execute this experiment run:
# python train.py experiment=example

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["LJ13"]

seed: 12345

logger:
  wandb:
    tags: ${tags}
    group: "lj13"

defaults:
  - override /energy: lj13
  - override /model/net: egnn_temp
  - override /model/noise_schedule: elucidating

model:
  partial_prior:
    _target_: src.energies.base_prior.MeanFreePrior
    _partial_: true
    n_particles: ${energy.n_particles}
    spatial_dim: ${energy.spatial_dim} 

  clipper:
    _target_: src.models.components.clipper.Clipper
    should_clip_scores: True
    should_clip_log_rewards: False
    max_score_norm: 1000
    min_log_reward: null
    n_particles: ${energy.n_particles}
    dimensionality: ${energy.dimensionality}
    spatial_dim: ${energy.spatial_dim}

  diffusion_scale: 1.0
  num_negative_time_steps: 1
  num_samples_to_sample_from_buffer: 512

  num_samples_to_save: 10000
  num_integration_steps: 1000

  # Elucidating noise schedule
  P_mean: -1.2
  P_std: 1.2

  # energytemp parameters
  num_init_samples: 10000
  test_batch_size: 5000
  num_eval_samples: 2048
  num_samples_to_generate_per_epoch: 5000
  inference_batch_size: 512
  resampling_interval: 1
  start_resampling_step: 0
  end_resampling_step: 995
  scale_diffusion: False
  resample_at_end: True

  temperatures:
    - 2.0
    - 1.5
    - 1.0
    - 0.9
    - 0.8
    - 0.7


  loss_weights:
    energy_score: 1.0
    score: 1.0
    energy_matching: 1.0
    target_score: 0.0
    dem_energy: 0.0

  init_from_prior: false

  num_mc_samples: 1000

  update_temp_epoch: 
    - 100
    - 300
    - 600
    - 1000
    - 1400
    - 1800
