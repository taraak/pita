[[36m2024-11-02 09:56:26,279[0m][[35mHYDRA[0m] Launching 1 jobs locally[0m
[[36m2024-11-02 09:56:26,280[0m][[35mHYDRA[0m] 	#0 : experiment=lj55 trainer=gpu[0m
[[36m2024-11-02 09:56:26,528[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2024-11-02 09:56:26,534[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.dummy.DummyDataModule                                
â”‚       n_train_batches_per_epoch: 100                                          
â”‚       n_val_batches_per_epoch: 4                                              
â”‚       n_test_batches_per_epoch: 1                                             
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ net:                                                                    
â”‚         _target_: src.models.components.egnn.EGNN_dynamics                    
â”‚         _partial_: true                                                       
â”‚         n_particles: 55                                                       
â”‚         n_dimension: 3                                                        
â”‚         hidden_nf: 128                                                        
â”‚         n_layers: 5                                                           
â”‚         act_fn:                                                               
â”‚           _target_: torch.nn.SiLU                                             
â”‚         recurrent: true                                                       
â”‚         tanh: true                                                            
â”‚         attention: true                                                       
â”‚         condition_time: true                                                  
â”‚         agg: sum                                                              
â”‚       noise_schedule:                                                         
â”‚         _target_: src.models.components.noise_schedules.GeometricNoiseSchedule
â”‚         sigma_min: 0.5                                                        
â”‚         sigma_max: 4                                                          
â”‚       _target_: src.models.dem_module.DEMLitModule                            
â”‚       optimizer:                                                              
â”‚         _target_: torch.optim.Adam                                            
â”‚         _partial_: true                                                       
â”‚         lr: 0.001                                                             
â”‚         weight_decay: 0.0                                                     
â”‚       scheduler:                                                              
â”‚         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
â”‚         _partial_: true                                                       
â”‚         mode: min                                                             
â”‚         factor: 0.1                                                           
â”‚         patience: 10                                                          
â”‚       partial_buffer:                                                         
â”‚         _target_: src.models.components.prioritised_replay_buffer.SimpleBuffer
â”‚         _partial_: true                                                       
â”‚         dim: 165                                                              
â”‚         max_length: 10000                                                     
â”‚         min_sample_length: 1000                                               
â”‚         initial_sampler: null                                                 
â”‚         sample_with_replacement: true                                         
â”‚         fill_buffer_during_init: false                                        
â”‚         prioritize: false                                                     
â”‚       score_scaler: null                                                      
â”‚       num_init_samples: 1024                                                  
â”‚       num_estimator_mc_samples: 100                                           
â”‚       num_samples_to_generate_per_epoch: 32                                   
â”‚       num_samples_to_sample_from_buffer: 128                                  
â”‚       eval_batch_size: 16                                                     
â”‚       num_integration_steps: 1000                                             
â”‚       nll_integration_method: dopri5                                          
â”‚       nll_with_cfm: false                                                     
â”‚       nll_with_dem: false                                                     
â”‚       nll_on_buffer: false                                                    
â”‚       cfm_sigma: 0.0                                                          
â”‚       cfm_prior_std: 1.0                                                      
â”‚       use_otcfm: false                                                        
â”‚       prioritize_cfm_training_samples: false                                  
â”‚       lr_scheduler_update_frequency: 20                                       
â”‚       input_scaling_factor: null                                              
â”‚       output_scaling_factor: null                                             
â”‚       compile: false                                                          
â”‚       use_richardsons: false                                                  
â”‚       cfm_loss_weight: 1.0                                                    
â”‚       use_ema: false                                                          
â”‚       use_exact_likelihood: true                                              
â”‚       debug_use_train_data: false                                             
â”‚       init_from_prior: true                                                   
â”‚       compute_nll_on_train_data: false                                        
â”‚       use_buffer: true                                                        
â”‚       logz_with_cfm: false                                                    
â”‚       num_samples_to_save: 100000                                             
â”‚       tol: 1.0e-05                                                            
â”‚       exact_hessian: false                                                    
â”‚       resampling_interval: 1                                                  
â”‚       partial_prior:                                                          
â”‚         _target_: src.energies.base_prior.MeanFreePrior                       
â”‚         _partial_: true                                                       
â”‚         n_particles: 55                                                       
â”‚         spatial_dim: 3                                                        
â”‚       lambda_weighter:                                                        
â”‚         _target_: src.models.components.lambda_weighter.NoLambdaWeighter      
â”‚         _partial_: true                                                       
â”‚       clipper:                                                                
â”‚         _target_: src.models.components.clipper.Clipper                       
â”‚         should_clip_scores: true                                              
â”‚         should_clip_log_rewards: false                                        
â”‚         max_score_norm: 20                                                    
â”‚         min_log_reward: null                                                  
â”‚       diffusion_scale: 1.0                                                    
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val/energy_w2                                                
â”‚         min_delta: 0.0                                                        
â”‚         patience: 10                                                          
â”‚         verbose: true                                                         
â”‚         mode: min                                                             
â”‚         strict: true                                                          
â”‚         check_finite: false                                                   
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚       model_checkpoint:                                                       
â”‚         dirpath: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multirun
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/nll                                                      
â”‚         mode: min                                                             
â”‚         every_n_epochs: 50                                                    
â”‚         save_last: true                                                       
â”‚         save_top_k: 3                                                         
â”‚         auto_insert_metric_name: false                                        
â”‚         verbose: true                                                         
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ wandb:                                                                  
â”‚         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
â”‚         save_dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiru
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: DEM-2                                                        
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         entity: openproblems-comp                                             
â”‚         group: lj55                                                           
â”‚         tags:                                                                 
â”‚         - LJ55                                                                
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/m
â”‚       min_epochs: 1                                                           
â”‚       max_epochs: 2000                                                        
â”‚       accelerator: cuda                                                       
â”‚       devices: 1                                                              
â”‚       check_val_every_n_epoch: 20                                             
â”‚       deterministic: false                                                    
â”‚       gradient_clip_val: 0.5                                                  
â”‚       inference_mode: false                                                   
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /home/mila/t/tara.akhoundsadegh/active_inference/runner       
â”‚       data_dir: /network/scratch/t/tara.akhoundsadegh/dem/data/               
â”‚       log_dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/                
â”‚       output_dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiru
â”‚       work_dir: /home/mila/t/tara.akhoundsadegh/active_inference/runner       
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                   
â”œâ”€â”€ run_name
â”‚   â””â”€â”€ default                                                                 
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['LJ55']                                                                
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 12345                                                                   
â””â”€â”€ energy
    â””â”€â”€ _target_: src.energies.lennardjones_energy.LennardJonesEnergy           
        _partial_: true                                                         
        dimensionality: 165                                                     
        n_particles: 55                                                         
        data_path: ../data/test_split_LJ55-1000-part1.npy                       
        data_path_train: ../data/train_split_LJ55-1000-part1.npy                
        data_path_val: ../data/val_split_LJ55-1000-part1.npy                    
        plot_samples_epoch_period: 1                                            
        data_normalization_factor: 1.0                                          
        is_molecule: true                                                       
                                                                                
[rank: 0] Seed set to 12345
[[36m2024-11-02 09:56:26,619[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.dummy.DummyDataModule>[0m
[[36m2024-11-02 09:56:26,624[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating energy function <src.energies.lennardjones_energy.LennardJonesEnergy>[0m
[[36m2024-11-02 09:56:31,784[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.dem_module.DEMLitModule>[0m
[[36m2024-11-02 09:56:34,516[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2024-11-02 09:56:34,516[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2024-11-02 09:56:34,518[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-02 09:56:34,518[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-02 09:56:34,520[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2024-11-02 09:56:34,520[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2024-11-02 09:56:34,526[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python src/train.py -m experiment=lj55 trainer=gpu ...
[[36m2024-11-02 09:56:34,586[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.[0m
[[36m2024-11-02 09:56:34,666[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - GPU available: True (cuda), used: True[0m
[[36m2024-11-02 09:56:34,668[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - TPU available: False, using: 0 TPU cores[0m
[[36m2024-11-02 09:56:34,668[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - HPU available: False, using: 0 HPUs[0m
[[36m2024-11-02 09:56:34,668[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: taraak (openproblems-comp). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiruns/2024-11-02_09-56-25/0/wandb/run-20241102_095637-td6j4vjl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-star-801
wandb: â­ï¸ View project at https://wandb.ai/openproblems-comp/DEM-2
wandb: ðŸš€ View run at https://wandb.ai/openproblems-comp/DEM-2/runs/td6j4vjl
[[36m2024-11-02 09:56:38,055[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python src/train.py -m experiment=lj55 trainer=gpu ...
[[36m2024-11-02 09:56:38,387[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.
Buffer not initialised, expected that checkpoint will be loaded.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ      Validate metric      â”ƒ       DataLoader 0        â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚     val/1-Wasserstein     â”‚     49.28855514526367     â”‚
â”‚     val/2-Wasserstein     â”‚    49.298892974853516     â”‚
â”‚        val/Eq-EMD2        â”‚    38.098854064941406     â”‚
â”‚      val/Linear_MMD       â”‚     2270.824951171875     â”‚
â”‚        val/Mean_L1        â”‚     1.383426308631897     â”‚
â”‚        val/Mean_L2        â”‚    1.8747661113739014     â”‚
â”‚       val/Mean_MSE        â”‚    3.5147480964660645     â”‚
â”‚       val/Median_L1       â”‚    1.8692433834075928     â”‚
â”‚       val/Median_L2       â”‚    2.4219393730163574     â”‚
â”‚      val/Median_MSE       â”‚     5.865790367126465     â”‚
â”‚       val/Poly_MMD        â”‚         5419529.5         â”‚
â”‚        val/RBF_MMD        â”‚    0.7128579616546631     â”‚
â”‚      val/loss_epoch       â”‚     49.46726989746094     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Validation â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0:05:14 â€¢ 0:00:00 0.00it/s 
[[36m2024-11-02 10:01:55,727[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Resuming training from checkpoint: None[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Buffer not initialised, expected that checkpoint will be loaded.
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ     â”ƒ Name                                 â”ƒ Type          â”ƒ Params â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0   â”‚ dem_train_loss                       â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 1   â”‚ cfm_train_loss                       â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 2   â”‚ val_loss                             â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 3   â”‚ test_loss                            â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 4   â”‚ val_nll_logdetjac                    â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 5   â”‚ test_nll_logdetjac                   â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 6   â”‚ val_nll_log_p_1                      â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 7   â”‚ test_nll_log_p_1                     â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 8   â”‚ val_nll                              â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 9   â”‚ test_nll                             â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 10  â”‚ val_nfe                              â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 11  â”‚ test_nfe                             â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 12  â”‚ val_energy_w2                        â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 13  â”‚ val_dist_w2                          â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 14  â”‚ val_dist_total_var                   â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 15  â”‚ val_dem_nll_logdetjac                â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 16  â”‚ test_dem_nll_logdetjac               â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 17  â”‚ val_dem_nll_log_p_1                  â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 18  â”‚ test_dem_nll_log_p_1                 â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 19  â”‚ val_dem_nll                          â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 20  â”‚ test_dem_nll                         â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 21  â”‚ val_dem_nfe                          â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 22  â”‚ test_dem_nfe                         â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 23  â”‚ val_dem_logz                         â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 24  â”‚ val_logz                             â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 25  â”‚ test_dem_logz                        â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 26  â”‚ test_logz                            â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 27  â”‚ val_buffer_nll_logdetjac             â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 28  â”‚ val_buffer_nll_log_p_1               â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 29  â”‚ val_buffer_nll                       â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 30  â”‚ val_buffer_nfe                       â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 31  â”‚ val_buffer_logz                      â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 32  â”‚ test_buffer_nll_logdetjac            â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 33  â”‚ test_buffer_nll_log_p_1              â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 34  â”‚ test_buffer_nll                      â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 35  â”‚ test_buffer_nfe                      â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 36  â”‚ test_buffer_logz                     â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 37  â”‚ val_train_nll_logdetjac              â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 38  â”‚ val_train_nll_log_p_1                â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 39  â”‚ val_train_nll                        â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 40  â”‚ val_train_nfe                        â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 41  â”‚ val_train_logz                       â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 42  â”‚ test_train_nll_logdetjac             â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 43  â”‚ test_train_nll_log_p_1               â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 44  â”‚ test_train_nll                       â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 45  â”‚ test_train_nfe                       â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 46  â”‚ test_train_logz                      â”‚ MeanMetric    â”‚      0 â”‚ train â”‚
â”‚ 47  â”‚ cfm_net                              â”‚ EGNN_dynamics â”‚  579 K â”‚ train â”‚
â”‚ 48  â”‚ cfm_net.egnn                         â”‚ EGNN          â”‚  579 K â”‚ train â”‚
â”‚ 49  â”‚ cfm_net.egnn.embedding               â”‚ Linear        â”‚    256 â”‚ train â”‚
â”‚ 50  â”‚ cfm_net.egnn.embedding_out           â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 51  â”‚ cfm_net.egnn.gcl_0                   â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 52  â”‚ cfm_net.egnn.gcl_0.edge_mlp          â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 53  â”‚ cfm_net.egnn.gcl_0.edge_mlp.0        â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 54  â”‚ cfm_net.egnn.gcl_0.edge_mlp.1        â”‚ SiLU          â”‚      0 â”‚ train â”‚
â”‚ 55  â”‚ cfm_net.egnn.gcl_0.edge_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 56  â”‚ cfm_net.egnn.gcl_0.node_mlp          â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 57  â”‚ cfm_net.egnn.gcl_0.node_mlp.0        â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 58  â”‚ cfm_net.egnn.gcl_0.node_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 59  â”‚ cfm_net.egnn.gcl_0.coord_mlp         â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 60  â”‚ cfm_net.egnn.gcl_0.coord_mlp.0       â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 61  â”‚ cfm_net.egnn.gcl_0.coord_mlp.2       â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 62  â”‚ cfm_net.egnn.gcl_0.coord_mlp.3       â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 63  â”‚ cfm_net.egnn.gcl_0.att_mlp           â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 64  â”‚ cfm_net.egnn.gcl_0.att_mlp.0         â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 65  â”‚ cfm_net.egnn.gcl_0.att_mlp.1         â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 66  â”‚ cfm_net.egnn.gcl_1                   â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 67  â”‚ cfm_net.egnn.gcl_1.edge_mlp          â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 68  â”‚ cfm_net.egnn.gcl_1.edge_mlp.0        â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 69  â”‚ cfm_net.egnn.gcl_1.edge_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 70  â”‚ cfm_net.egnn.gcl_1.node_mlp          â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 71  â”‚ cfm_net.egnn.gcl_1.node_mlp.0        â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 72  â”‚ cfm_net.egnn.gcl_1.node_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 73  â”‚ cfm_net.egnn.gcl_1.coord_mlp         â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 74  â”‚ cfm_net.egnn.gcl_1.coord_mlp.0       â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 75  â”‚ cfm_net.egnn.gcl_1.coord_mlp.2       â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 76  â”‚ cfm_net.egnn.gcl_1.coord_mlp.3       â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 77  â”‚ cfm_net.egnn.gcl_1.att_mlp           â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 78  â”‚ cfm_net.egnn.gcl_1.att_mlp.0         â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 79  â”‚ cfm_net.egnn.gcl_1.att_mlp.1         â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 80  â”‚ cfm_net.egnn.gcl_2                   â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 81  â”‚ cfm_net.egnn.gcl_2.edge_mlp          â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 82  â”‚ cfm_net.egnn.gcl_2.edge_mlp.0        â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 83  â”‚ cfm_net.egnn.gcl_2.edge_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 84  â”‚ cfm_net.egnn.gcl_2.node_mlp          â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 85  â”‚ cfm_net.egnn.gcl_2.node_mlp.0        â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 86  â”‚ cfm_net.egnn.gcl_2.node_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 87  â”‚ cfm_net.egnn.gcl_2.coord_mlp         â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 88  â”‚ cfm_net.egnn.gcl_2.coord_mlp.0       â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 89  â”‚ cfm_net.egnn.gcl_2.coord_mlp.2       â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 90  â”‚ cfm_net.egnn.gcl_2.coord_mlp.3       â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 91  â”‚ cfm_net.egnn.gcl_2.att_mlp           â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 92  â”‚ cfm_net.egnn.gcl_2.att_mlp.0         â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 93  â”‚ cfm_net.egnn.gcl_2.att_mlp.1         â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 94  â”‚ cfm_net.egnn.gcl_3                   â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 95  â”‚ cfm_net.egnn.gcl_3.edge_mlp          â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 96  â”‚ cfm_net.egnn.gcl_3.edge_mlp.0        â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 97  â”‚ cfm_net.egnn.gcl_3.edge_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 98  â”‚ cfm_net.egnn.gcl_3.node_mlp          â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 99  â”‚ cfm_net.egnn.gcl_3.node_mlp.0        â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 100 â”‚ cfm_net.egnn.gcl_3.node_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 101 â”‚ cfm_net.egnn.gcl_3.coord_mlp         â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 102 â”‚ cfm_net.egnn.gcl_3.coord_mlp.0       â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 103 â”‚ cfm_net.egnn.gcl_3.coord_mlp.2       â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 104 â”‚ cfm_net.egnn.gcl_3.coord_mlp.3       â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 105 â”‚ cfm_net.egnn.gcl_3.att_mlp           â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 106 â”‚ cfm_net.egnn.gcl_3.att_mlp.0         â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 107 â”‚ cfm_net.egnn.gcl_3.att_mlp.1         â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 108 â”‚ cfm_net.egnn.gcl_4                   â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 109 â”‚ cfm_net.egnn.gcl_4.edge_mlp          â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 110 â”‚ cfm_net.egnn.gcl_4.edge_mlp.0        â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 111 â”‚ cfm_net.egnn.gcl_4.edge_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 112 â”‚ cfm_net.egnn.gcl_4.node_mlp          â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 113 â”‚ cfm_net.egnn.gcl_4.node_mlp.0        â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 114 â”‚ cfm_net.egnn.gcl_4.node_mlp.2        â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 115 â”‚ cfm_net.egnn.gcl_4.coord_mlp         â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 116 â”‚ cfm_net.egnn.gcl_4.coord_mlp.0       â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 117 â”‚ cfm_net.egnn.gcl_4.coord_mlp.2       â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 118 â”‚ cfm_net.egnn.gcl_4.coord_mlp.3       â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 119 â”‚ cfm_net.egnn.gcl_4.att_mlp           â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 120 â”‚ cfm_net.egnn.gcl_4.att_mlp.0         â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 121 â”‚ cfm_net.egnn.gcl_4.att_mlp.1         â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 122 â”‚ net                                  â”‚ EnergyModel   â”‚  579 K â”‚ train â”‚
â”‚ 123 â”‚ net.score_net                        â”‚ EGNN_dynamics â”‚  579 K â”‚ train â”‚
â”‚ 124 â”‚ net.score_net.egnn                   â”‚ EGNN          â”‚  579 K â”‚ train â”‚
â”‚ 125 â”‚ net.score_net.egnn.embedding         â”‚ Linear        â”‚    256 â”‚ train â”‚
â”‚ 126 â”‚ net.score_net.egnn.embedding_out     â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 127 â”‚ net.score_net.egnn.gcl_0             â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 128 â”‚ net.score_net.egnn.gcl_0.edge_mlp    â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 129 â”‚ net.score_net.egnn.gcl_0.edge_mlp.0  â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 130 â”‚ net.score_net.egnn.gcl_0.edge_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 131 â”‚ net.score_net.egnn.gcl_0.node_mlp    â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 132 â”‚ net.score_net.egnn.gcl_0.node_mlp.0  â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 133 â”‚ net.score_net.egnn.gcl_0.node_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 134 â”‚ net.score_net.egnn.gcl_0.coord_mlp   â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 135 â”‚ net.score_net.egnn.gcl_0.coord_mlp.0 â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 136 â”‚ net.score_net.egnn.gcl_0.coord_mlp.2 â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 137 â”‚ net.score_net.egnn.gcl_0.coord_mlp.3 â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 138 â”‚ net.score_net.egnn.gcl_0.att_mlp     â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 139 â”‚ net.score_net.egnn.gcl_0.att_mlp.0   â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 140 â”‚ net.score_net.egnn.gcl_0.att_mlp.1   â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 141 â”‚ net.score_net.egnn.gcl_1             â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 142 â”‚ net.score_net.egnn.gcl_1.edge_mlp    â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 143 â”‚ net.score_net.egnn.gcl_1.edge_mlp.0  â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 144 â”‚ net.score_net.egnn.gcl_1.edge_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 145 â”‚ net.score_net.egnn.gcl_1.node_mlp    â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 146 â”‚ net.score_net.egnn.gcl_1.node_mlp.0  â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 147 â”‚ net.score_net.egnn.gcl_1.node_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 148 â”‚ net.score_net.egnn.gcl_1.coord_mlp   â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 149 â”‚ net.score_net.egnn.gcl_1.coord_mlp.0 â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 150 â”‚ net.score_net.egnn.gcl_1.coord_mlp.2 â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 151 â”‚ net.score_net.egnn.gcl_1.coord_mlp.3 â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 152 â”‚ net.score_net.egnn.gcl_1.att_mlp     â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 153 â”‚ net.score_net.egnn.gcl_1.att_mlp.0   â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 154 â”‚ net.score_net.egnn.gcl_1.att_mlp.1   â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 155 â”‚ net.score_net.egnn.gcl_2             â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 156 â”‚ net.score_net.egnn.gcl_2.edge_mlp    â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 157 â”‚ net.score_net.egnn.gcl_2.edge_mlp.0  â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 158 â”‚ net.score_net.egnn.gcl_2.edge_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 159 â”‚ net.score_net.egnn.gcl_2.node_mlp    â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 160 â”‚ net.score_net.egnn.gcl_2.node_mlp.0  â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 161 â”‚ net.score_net.egnn.gcl_2.node_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 162 â”‚ net.score_net.egnn.gcl_2.coord_mlp   â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 163 â”‚ net.score_net.egnn.gcl_2.coord_mlp.0 â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 164 â”‚ net.score_net.egnn.gcl_2.coord_mlp.2 â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 165 â”‚ net.score_net.egnn.gcl_2.coord_mlp.3 â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 166 â”‚ net.score_net.egnn.gcl_2.att_mlp     â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 167 â”‚ net.score_net.egnn.gcl_2.att_mlp.0   â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 168 â”‚ net.score_net.egnn.gcl_2.att_mlp.1   â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 169 â”‚ net.score_net.egnn.gcl_3             â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 170 â”‚ net.score_net.egnn.gcl_3.edge_mlp    â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 171 â”‚ net.score_net.egnn.gcl_3.edge_mlp.0  â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 172 â”‚ net.score_net.egnn.gcl_3.edge_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 173 â”‚ net.score_net.egnn.gcl_3.node_mlp    â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 174 â”‚ net.score_net.egnn.gcl_3.node_mlp.0  â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 175 â”‚ net.score_net.egnn.gcl_3.node_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 176 â”‚ net.score_net.egnn.gcl_3.coord_mlp   â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 177 â”‚ net.score_net.egnn.gcl_3.coord_mlp.0 â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 178 â”‚ net.score_net.egnn.gcl_3.coord_mlp.2 â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 179 â”‚ net.score_net.egnn.gcl_3.coord_mlp.3 â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 180 â”‚ net.score_net.egnn.gcl_3.att_mlp     â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 181 â”‚ net.score_net.egnn.gcl_3.att_mlp.0   â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 182 â”‚ net.score_net.egnn.gcl_3.att_mlp.1   â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 183 â”‚ net.score_net.egnn.gcl_4             â”‚ E_GCL         â”‚  115 K â”‚ train â”‚
â”‚ 184 â”‚ net.score_net.egnn.gcl_4.edge_mlp    â”‚ Sequential    â”‚ 49.7 K â”‚ train â”‚
â”‚ 185 â”‚ net.score_net.egnn.gcl_4.edge_mlp.0  â”‚ Linear        â”‚ 33.2 K â”‚ train â”‚
â”‚ 186 â”‚ net.score_net.egnn.gcl_4.edge_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 187 â”‚ net.score_net.egnn.gcl_4.node_mlp    â”‚ Sequential    â”‚ 49.4 K â”‚ train â”‚
â”‚ 188 â”‚ net.score_net.egnn.gcl_4.node_mlp.0  â”‚ Linear        â”‚ 32.9 K â”‚ train â”‚
â”‚ 189 â”‚ net.score_net.egnn.gcl_4.node_mlp.2  â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 190 â”‚ net.score_net.egnn.gcl_4.coord_mlp   â”‚ Sequential    â”‚ 16.6 K â”‚ train â”‚
â”‚ 191 â”‚ net.score_net.egnn.gcl_4.coord_mlp.0 â”‚ Linear        â”‚ 16.5 K â”‚ train â”‚
â”‚ 192 â”‚ net.score_net.egnn.gcl_4.coord_mlp.2 â”‚ Linear        â”‚    128 â”‚ train â”‚
â”‚ 193 â”‚ net.score_net.egnn.gcl_4.coord_mlp.3 â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 194 â”‚ net.score_net.egnn.gcl_4.att_mlp     â”‚ Sequential    â”‚    129 â”‚ train â”‚
â”‚ 195 â”‚ net.score_net.egnn.gcl_4.att_mlp.0   â”‚ Linear        â”‚    129 â”‚ train â”‚
â”‚ 196 â”‚ net.score_net.egnn.gcl_4.att_mlp.1   â”‚ Sigmoid       â”‚      0 â”‚ train â”‚
â”‚ 197 â”‚ reverse_sde                          â”‚ VEReverseSDE  â”‚  579 K â”‚ train â”‚
â”‚ 198 â”‚ dem_cnf                              â”‚ CNF           â”‚  579 K â”‚ train â”‚
â”‚ 199 â”‚ cfm_cnf                              â”‚ CNF           â”‚  579 K â”‚ train â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 1.2 M                                                         
Non-trainable params: 0                                                         
Total params: 1.2 M                                                             
Total estimated model params size (MB): 4                                       
Modules in train mode: 200                                                      
Modules in eval mode: 0                                                         
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/numpy/lib/histograms.py:885: RuntimeWarning: invalid value encountered in divide
  return n/db/n.sum(), bin_edges
Metric val/energy_w2 improved. New best score: 96125.398
/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py:590: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  idx = torch.randint(0, logweights.shape[1], (15,))
Metric val/energy_w2 improved by 13888.445 >= min_delta = 0.0. New best score: 82236.953
Metric val/energy_w2 improved by 12188.906 >= min_delta = 0.0. New best score: 70048.047
Metric val/energy_w2 improved by 33616.547 >= min_delta = 0.0. New best score: 36431.500
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [0,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [1,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [2,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [3,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [4,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [5,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [6,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [7,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [8,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [9,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [10,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [11,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [12,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [13,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [14,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [15,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [16,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [17,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [18,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [19,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [20,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [21,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [22,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [23,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [24,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [25,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [26,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [27,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [28,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [29,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [30,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [31,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
Epoch 90/1999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100/100 0:00:36 â€¢       2.72it/s v_num: 4vjl      
                                      0:00:00                  train/dem_loss:  
                                                               958.344          
                                                               val/energy_w2:   
                                                               4993316875805301â€¦
                                                               val/dist_w2:     
                                                               180.992          
                                                               val/dist_total_vâ€¦
                                                               0.668            
                                                               val/loss_step:   
                                                               74.256           
                                                               val/loss_epoch:  
                                                               58.792           
[[36m2024-11-02 14:29:12,173[0m][[34msrc.utils.utils[0m][[31mERROR[0m] - [rank: 0] [0m
Traceback (most recent call last):
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 206, in run
    self.on_advance_end()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 377, in on_advance_end
    call._call_lightning_module_hook(trainer, "on_train_epoch_end")
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 568, in on_train_epoch_end
    return_logweights=True
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 499, in generate_samples
    samples, logweights = self.integrate(
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 524, in integrate
    trajectory, logweights = integrate_sde(
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sde_integration.py", line 149, in integrate_sde
    x, a, a_plot = euler_maruyama_step(sde, t, x, a,
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sde_integration.py", line 32, in euler_maruyama_step
    drift_Xt, drift_At = sde.f(t, x, resampling_interval)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sdes.py", line 38, in f
    t = t * torch.ones(x.shape[0]).to(x.device)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/utils/utils.py", line 68, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/train.py", line 106, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 68, in _call_and_handle_interrupt
    trainer._teardown()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1004, in _teardown
    self.strategy.teardown()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 531, in teardown
    _optimizers_to_device(self.optimizers, torch.device("cpu"))
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 28, in _optimizers_to_device
    _optimizer_to_device(opt, device)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 42, in _optimizer_to_device
    v[key] = move_data_to_device(val, device)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 110, in move_data_to_device
    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 104, in batch_to
    data_output = data.to(device, **kwargs)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[[36m2024-11-02 14:29:12,200[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiruns/2024-11-02_09-56-25/0[0m
[[36m2024-11-02 14:29:12,200[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: - 1.653 MB of 1.653 MB uploadedwandb: \ 1.653 MB of 1.653 MB uploadedwandb: | 1.653 MB of 1.653 MB uploadedwandb: / 1.685 MB of 1.727 MB uploaded (0.004 MB deduped)wandb: - 1.685 MB of 1.727 MB uploaded (0.004 MB deduped)wandb: \ 1.727 MB of 1.727 MB uploaded (0.004 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                   epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                          train/dem_loss â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb: train/stratified/dem_loss t=[0.00,0.20) â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb: train/stratified/dem_loss t=[0.20,0.40) â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb: train/stratified/dem_loss t=[0.40,0.60) â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–ˆ
wandb: train/stratified/dem_loss t=[0.60,0.80) â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb: train/stratified/dem_loss t=[0.80,1.00) â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:                     trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:                       val/1-Wasserstein â–ˆâ–â–â–â–
wandb:                       val/2-Wasserstein â–ˆâ–â–â–â–
wandb:                             val/Eq-EMD2 â–ˆâ–â–â–â–
wandb:                          val/Linear_MMD â–ˆâ–â–â–â–
wandb:                             val/Mean_L1 â–ˆâ–ƒâ–‚â–â–
wandb:                             val/Mean_L2 â–ˆâ–ƒâ–‚â–â–
wandb:                            val/Mean_MSE â–ˆâ–‚â–‚â–â–
wandb:                           val/Median_L1 â–ˆâ–‚â–‚â–â–
wandb:                           val/Median_L2 â–ˆâ–‚â–‚â–â–
wandb:                          val/Median_MSE â–ˆâ–‚â–‚â–â–
wandb:                            val/Poly_MMD â–ˆâ–â–â–â–
wandb:                             val/RBF_MMD â–â–‡â–‡â–‡â–ˆ
wandb:                      val/dist_total_var â–…â–‚â–„â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–„â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆ
wandb:                             val/dist_w2 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆ
wandb:                           val/energy_w2 â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                          val/loss_epoch â–â–„â–„â–â–ˆ
wandb:                           val/loss_step â–ƒâ–…â–ƒâ–‚â–â–„â–ˆâ–„â–„â–…â–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–…â–†â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:                                   epoch 90
wandb:                          train/dem_loss 3130.96094
wandb: train/stratified/dem_loss t=[0.00,0.20) 83.4585
wandb: train/stratified/dem_loss t=[0.20,0.40) 54.93658
wandb: train/stratified/dem_loss t=[0.40,0.60) 22.91642
wandb: train/stratified/dem_loss t=[0.60,0.80) 18.16203
wandb: train/stratified/dem_loss t=[0.80,1.00) 20.64707
wandb:                     trainer/global_step 9099
wandb:                       val/1-Wasserstein 19.27489
wandb:                       val/2-Wasserstein 19.29245
wandb:                             val/Eq-EMD2 5.155
wandb:                          val/Linear_MMD 207.41075
wandb:                             val/Mean_L1 0.95516
wandb:                             val/Mean_L2 1.13558
wandb:                            val/Mean_MSE 1.28955
wandb:                           val/Median_L1 0.96447
wandb:                           val/Median_L2 1.14949
wandb:                          val/Median_MSE 1.32133
wandb:                            val/Poly_MMD 44124.42969
wandb:                             val/RBF_MMD 1.60229
wandb:                      val/dist_total_var 0.66776
wandb:                             val/dist_w2 180.99203
wandb:                           val/energy_w2 4.993316875805302e+33
wandb:                          val/loss_epoch 58.79182
wandb:                           val/loss_step 74.25627
wandb: 
wandb: ðŸš€ View run desert-star-801 at: https://wandb.ai/openproblems-comp/DEM-2/runs/td6j4vjl
wandb: ï¸âš¡ View job at https://wandb.ai/openproblems-comp/DEM-2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQxODUwNzQ1NA==/version_details/v80
wandb: Synced 5 W&B file(s), 94 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiruns/2024-11-02_09-56-25/0/wandb/run-20241102_095637-td6j4vjl/logs
Error executing job with overrides: ['experiment=lj55', 'trainer=gpu']
Traceback (most recent call last):
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 206, in run
    self.on_advance_end()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 377, in on_advance_end
    call._call_lightning_module_hook(trainer, "on_train_epoch_end")
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 568, in on_train_epoch_end
    return_logweights=True
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 499, in generate_samples
    samples, logweights = self.integrate(
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 524, in integrate
    trajectory, logweights = integrate_sde(
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sde_integration.py", line 149, in integrate_sde
    x, a, a_plot = euler_maruyama_step(sde, t, x, a,
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sde_integration.py", line 32, in euler_maruyama_step
    drift_Xt, drift_At = sde.f(t, x, resampling_interval)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sdes.py", line 38, in f
    t = t * torch.ones(x.shape[0]).to(x.device)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/train.py", line 139, in main
    metric_dict, _ = train(cfg)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/utils/utils.py", line 78, in wrap
    raise ex
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/utils/utils.py", line 68, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/train.py", line 106, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 68, in _call_and_handle_interrupt
    trainer._teardown()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1004, in _teardown
    self.strategy.teardown()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 531, in teardown
    _optimizers_to_device(self.optimizers, torch.device("cpu"))
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 28, in _optimizers_to_device
    _optimizer_to_device(opt, device)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 42, in _optimizer_to_device
    v[key] = move_data_to_device(val, device)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 110, in move_data_to_device
    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 104, in batch_to
    data_output = data.to(device, **kwargs)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.

======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Sat Nov  2 14:29:25 2024
Driver Version                            : 535.161.08
CUDA Version                              : 12.2

Attached GPUs                             : 1
GPU 00000000:90:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 97349
            GPU Utilization               : 97 %
            Memory Utilization            : 78 %
            Max memory usage              : 30316 MiB
            Time                          : 16370955 ms
            Is Running                    : 0

Sat Nov  2 14:29:25 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:90:00.0 Off |                    0 |
| N/A   45C    P0              72W / 400W |      0MiB / 40960MiB |     31%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
