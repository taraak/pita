[[36m2024-11-02 09:56:26,279[0m][[35mHYDRA[0m] Launching 1 jobs locally[0m
[[36m2024-11-02 09:56:26,280[0m][[35mHYDRA[0m] 	#0 : experiment=lj55 trainer=gpu[0m
[[36m2024-11-02 09:56:26,528[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2024-11-02 09:56:26,534[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
├── data
│   └── _target_: src.data.dummy.DummyDataModule                                
│       n_train_batches_per_epoch: 100                                          
│       n_val_batches_per_epoch: 4                                              
│       n_test_batches_per_epoch: 1                                             
│                                                                               
├── model
│   └── net:                                                                    
│         _target_: src.models.components.egnn.EGNN_dynamics                    
│         _partial_: true                                                       
│         n_particles: 55                                                       
│         n_dimension: 3                                                        
│         hidden_nf: 128                                                        
│         n_layers: 5                                                           
│         act_fn:                                                               
│           _target_: torch.nn.SiLU                                             
│         recurrent: true                                                       
│         tanh: true                                                            
│         attention: true                                                       
│         condition_time: true                                                  
│         agg: sum                                                              
│       noise_schedule:                                                         
│         _target_: src.models.components.noise_schedules.GeometricNoiseSchedule
│         sigma_min: 0.5                                                        
│         sigma_max: 4                                                          
│       _target_: src.models.dem_module.DEMLitModule                            
│       optimizer:                                                              
│         _target_: torch.optim.Adam                                            
│         _partial_: true                                                       
│         lr: 0.001                                                             
│         weight_decay: 0.0                                                     
│       scheduler:                                                              
│         _target_: torch.optim.lr_scheduler.ReduceLROnPlateau                  
│         _partial_: true                                                       
│         mode: min                                                             
│         factor: 0.1                                                           
│         patience: 10                                                          
│       partial_buffer:                                                         
│         _target_: src.models.components.prioritised_replay_buffer.SimpleBuffer
│         _partial_: true                                                       
│         dim: 165                                                              
│         max_length: 10000                                                     
│         min_sample_length: 1000                                               
│         initial_sampler: null                                                 
│         sample_with_replacement: true                                         
│         fill_buffer_during_init: false                                        
│         prioritize: false                                                     
│       score_scaler: null                                                      
│       num_init_samples: 1024                                                  
│       num_estimator_mc_samples: 100                                           
│       num_samples_to_generate_per_epoch: 32                                   
│       num_samples_to_sample_from_buffer: 128                                  
│       eval_batch_size: 16                                                     
│       num_integration_steps: 1000                                             
│       nll_integration_method: dopri5                                          
│       nll_with_cfm: false                                                     
│       nll_with_dem: false                                                     
│       nll_on_buffer: false                                                    
│       cfm_sigma: 0.0                                                          
│       cfm_prior_std: 1.0                                                      
│       use_otcfm: false                                                        
│       prioritize_cfm_training_samples: false                                  
│       lr_scheduler_update_frequency: 20                                       
│       input_scaling_factor: null                                              
│       output_scaling_factor: null                                             
│       compile: false                                                          
│       use_richardsons: false                                                  
│       cfm_loss_weight: 1.0                                                    
│       use_ema: false                                                          
│       use_exact_likelihood: true                                              
│       debug_use_train_data: false                                             
│       init_from_prior: true                                                   
│       compute_nll_on_train_data: false                                        
│       use_buffer: true                                                        
│       logz_with_cfm: false                                                    
│       num_samples_to_save: 100000                                             
│       tol: 1.0e-05                                                            
│       exact_hessian: false                                                    
│       resampling_interval: 1                                                  
│       partial_prior:                                                          
│         _target_: src.energies.base_prior.MeanFreePrior                       
│         _partial_: true                                                       
│         n_particles: 55                                                       
│         spatial_dim: 3                                                        
│       lambda_weighter:                                                        
│         _target_: src.models.components.lambda_weighter.NoLambdaWeighter      
│         _partial_: true                                                       
│       clipper:                                                                
│         _target_: src.models.components.clipper.Clipper                       
│         should_clip_scores: true                                              
│         should_clip_log_rewards: false                                        
│         max_score_norm: 20                                                    
│         min_log_reward: null                                                  
│       diffusion_scale: 1.0                                                    
│                                                                               
├── callbacks
│   └── early_stopping:                                                         
│         _target_: lightning.pytorch.callbacks.EarlyStopping                   
│         monitor: val/energy_w2                                                
│         min_delta: 0.0                                                        
│         patience: 10                                                          
│         verbose: true                                                         
│         mode: min                                                             
│         strict: true                                                          
│         check_finite: false                                                   
│         stopping_threshold: null                                              
│         divergence_threshold: null                                            
│         check_on_train_epoch_end: null                                        
│       model_summary:                                                          
│         _target_: lightning.pytorch.callbacks.RichModelSummary                
│         max_depth: -1                                                         
│       rich_progress_bar:                                                      
│         _target_: lightning.pytorch.callbacks.RichProgressBar                 
│       model_checkpoint:                                                       
│         dirpath: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multirun
│         filename: epoch_{epoch:03d}                                           
│         monitor: val/nll                                                      
│         mode: min                                                             
│         every_n_epochs: 50                                                    
│         save_last: true                                                       
│         save_top_k: 3                                                         
│         auto_insert_metric_name: false                                        
│         verbose: true                                                         
│                                                                               
├── logger
│   └── wandb:                                                                  
│         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
│         save_dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiru
│         offline: false                                                        
│         id: null                                                              
│         anonymous: null                                                       
│         project: DEM-2                                                        
│         log_model: false                                                      
│         prefix: ''                                                            
│         entity: openproblems-comp                                             
│         group: lj55                                                           
│         tags:                                                                 
│         - LJ55                                                                
│         job_type: ''                                                          
│                                                                               
├── trainer
│   └── _target_: lightning.pytorch.trainer.Trainer                             
│       default_root_dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/m
│       min_epochs: 1                                                           
│       max_epochs: 2000                                                        
│       accelerator: cuda                                                       
│       devices: 1                                                              
│       check_val_every_n_epoch: 20                                             
│       deterministic: false                                                    
│       gradient_clip_val: 0.5                                                  
│       inference_mode: false                                                   
│                                                                               
├── paths
│   └── root_dir: /home/mila/t/tara.akhoundsadegh/active_inference/runner       
│       data_dir: /network/scratch/t/tara.akhoundsadegh/dem/data/               
│       log_dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/                
│       output_dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiru
│       work_dir: /home/mila/t/tara.akhoundsadegh/active_inference/runner       
│                                                                               
├── extras
│   └── ignore_warnings: false                                                  
│       enforce_tags: true                                                      
│       print_config: true                                                      
│                                                                               
├── task_name
│   └── train                                                                   
├── run_name
│   └── default                                                                 
├── tags
│   └── ['LJ55']                                                                
├── train
│   └── True                                                                    
├── test
│   └── True                                                                    
├── ckpt_path
│   └── None                                                                    
├── seed
│   └── 12345                                                                   
└── energy
    └── _target_: src.energies.lennardjones_energy.LennardJonesEnergy           
        _partial_: true                                                         
        dimensionality: 165                                                     
        n_particles: 55                                                         
        data_path: ../data/test_split_LJ55-1000-part1.npy                       
        data_path_train: ../data/train_split_LJ55-1000-part1.npy                
        data_path_val: ../data/val_split_LJ55-1000-part1.npy                    
        plot_samples_epoch_period: 1                                            
        data_normalization_factor: 1.0                                          
        is_molecule: true                                                       
                                                                                
[rank: 0] Seed set to 12345
[[36m2024-11-02 09:56:26,619[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.dummy.DummyDataModule>[0m
[[36m2024-11-02 09:56:26,624[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating energy function <src.energies.lennardjones_energy.LennardJonesEnergy>[0m
[[36m2024-11-02 09:56:31,784[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.dem_module.DEMLitModule>[0m
[[36m2024-11-02 09:56:34,516[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2024-11-02 09:56:34,516[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2024-11-02 09:56:34,518[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2024-11-02 09:56:34,518[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2024-11-02 09:56:34,520[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2024-11-02 09:56:34,520[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2024-11-02 09:56:34,526[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python src/train.py -m experiment=lj55 trainer=gpu ...
[[36m2024-11-02 09:56:34,586[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.[0m
[[36m2024-11-02 09:56:34,666[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - GPU available: True (cuda), used: True[0m
[[36m2024-11-02 09:56:34,668[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - TPU available: False, using: 0 TPU cores[0m
[[36m2024-11-02 09:56:34,668[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - HPU available: False, using: 0 HPUs[0m
[[36m2024-11-02 09:56:34,668[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: taraak (openproblems-comp). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiruns/2024-11-02_09-56-25/0/wandb/run-20241102_095637-td6j4vjl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-star-801
wandb: ⭐️ View project at https://wandb.ai/openproblems-comp/DEM-2
wandb: 🚀 View run at https://wandb.ai/openproblems-comp/DEM-2/runs/td6j4vjl
[[36m2024-11-02 09:56:38,055[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python src/train.py -m experiment=lj55 trainer=gpu ...
[[36m2024-11-02 09:56:38,387[0m][[34mpytorch_lightning.utilities.rank_zero[0m][[32mINFO[0m] - You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.
Buffer not initialised, expected that checkpoint will be loaded.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃      Validate metric      ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│     val/1-Wasserstein     │     49.28855514526367     │
│     val/2-Wasserstein     │    49.298892974853516     │
│        val/Eq-EMD2        │    38.098854064941406     │
│      val/Linear_MMD       │     2270.824951171875     │
│        val/Mean_L1        │     1.383426308631897     │
│        val/Mean_L2        │    1.8747661113739014     │
│       val/Mean_MSE        │    3.5147480964660645     │
│       val/Median_L1       │    1.8692433834075928     │
│       val/Median_L2       │    2.4219393730163574     │
│      val/Median_MSE       │     5.865790367126465     │
│       val/Poly_MMD        │         5419529.5         │
│        val/RBF_MMD        │    0.7128579616546631     │
│      val/loss_epoch       │     49.46726989746094     │
└───────────────────────────┴───────────────────────────┘
Validation ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4/4 0:05:14 • 0:00:00 0.00it/s 
[[36m2024-11-02 10:01:55,727[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Resuming training from checkpoint: None[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Buffer not initialised, expected that checkpoint will be loaded.
┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃     ┃ Name                                 ┃ Type          ┃ Params ┃ Mode  ┃
┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0   │ dem_train_loss                       │ MeanMetric    │      0 │ train │
│ 1   │ cfm_train_loss                       │ MeanMetric    │      0 │ train │
│ 2   │ val_loss                             │ MeanMetric    │      0 │ train │
│ 3   │ test_loss                            │ MeanMetric    │      0 │ train │
│ 4   │ val_nll_logdetjac                    │ MeanMetric    │      0 │ train │
│ 5   │ test_nll_logdetjac                   │ MeanMetric    │      0 │ train │
│ 6   │ val_nll_log_p_1                      │ MeanMetric    │      0 │ train │
│ 7   │ test_nll_log_p_1                     │ MeanMetric    │      0 │ train │
│ 8   │ val_nll                              │ MeanMetric    │      0 │ train │
│ 9   │ test_nll                             │ MeanMetric    │      0 │ train │
│ 10  │ val_nfe                              │ MeanMetric    │      0 │ train │
│ 11  │ test_nfe                             │ MeanMetric    │      0 │ train │
│ 12  │ val_energy_w2                        │ MeanMetric    │      0 │ train │
│ 13  │ val_dist_w2                          │ MeanMetric    │      0 │ train │
│ 14  │ val_dist_total_var                   │ MeanMetric    │      0 │ train │
│ 15  │ val_dem_nll_logdetjac                │ MeanMetric    │      0 │ train │
│ 16  │ test_dem_nll_logdetjac               │ MeanMetric    │      0 │ train │
│ 17  │ val_dem_nll_log_p_1                  │ MeanMetric    │      0 │ train │
│ 18  │ test_dem_nll_log_p_1                 │ MeanMetric    │      0 │ train │
│ 19  │ val_dem_nll                          │ MeanMetric    │      0 │ train │
│ 20  │ test_dem_nll                         │ MeanMetric    │      0 │ train │
│ 21  │ val_dem_nfe                          │ MeanMetric    │      0 │ train │
│ 22  │ test_dem_nfe                         │ MeanMetric    │      0 │ train │
│ 23  │ val_dem_logz                         │ MeanMetric    │      0 │ train │
│ 24  │ val_logz                             │ MeanMetric    │      0 │ train │
│ 25  │ test_dem_logz                        │ MeanMetric    │      0 │ train │
│ 26  │ test_logz                            │ MeanMetric    │      0 │ train │
│ 27  │ val_buffer_nll_logdetjac             │ MeanMetric    │      0 │ train │
│ 28  │ val_buffer_nll_log_p_1               │ MeanMetric    │      0 │ train │
│ 29  │ val_buffer_nll                       │ MeanMetric    │      0 │ train │
│ 30  │ val_buffer_nfe                       │ MeanMetric    │      0 │ train │
│ 31  │ val_buffer_logz                      │ MeanMetric    │      0 │ train │
│ 32  │ test_buffer_nll_logdetjac            │ MeanMetric    │      0 │ train │
│ 33  │ test_buffer_nll_log_p_1              │ MeanMetric    │      0 │ train │
│ 34  │ test_buffer_nll                      │ MeanMetric    │      0 │ train │
│ 35  │ test_buffer_nfe                      │ MeanMetric    │      0 │ train │
│ 36  │ test_buffer_logz                     │ MeanMetric    │      0 │ train │
│ 37  │ val_train_nll_logdetjac              │ MeanMetric    │      0 │ train │
│ 38  │ val_train_nll_log_p_1                │ MeanMetric    │      0 │ train │
│ 39  │ val_train_nll                        │ MeanMetric    │      0 │ train │
│ 40  │ val_train_nfe                        │ MeanMetric    │      0 │ train │
│ 41  │ val_train_logz                       │ MeanMetric    │      0 │ train │
│ 42  │ test_train_nll_logdetjac             │ MeanMetric    │      0 │ train │
│ 43  │ test_train_nll_log_p_1               │ MeanMetric    │      0 │ train │
│ 44  │ test_train_nll                       │ MeanMetric    │      0 │ train │
│ 45  │ test_train_nfe                       │ MeanMetric    │      0 │ train │
│ 46  │ test_train_logz                      │ MeanMetric    │      0 │ train │
│ 47  │ cfm_net                              │ EGNN_dynamics │  579 K │ train │
│ 48  │ cfm_net.egnn                         │ EGNN          │  579 K │ train │
│ 49  │ cfm_net.egnn.embedding               │ Linear        │    256 │ train │
│ 50  │ cfm_net.egnn.embedding_out           │ Linear        │    129 │ train │
│ 51  │ cfm_net.egnn.gcl_0                   │ E_GCL         │  115 K │ train │
│ 52  │ cfm_net.egnn.gcl_0.edge_mlp          │ Sequential    │ 49.7 K │ train │
│ 53  │ cfm_net.egnn.gcl_0.edge_mlp.0        │ Linear        │ 33.2 K │ train │
│ 54  │ cfm_net.egnn.gcl_0.edge_mlp.1        │ SiLU          │      0 │ train │
│ 55  │ cfm_net.egnn.gcl_0.edge_mlp.2        │ Linear        │ 16.5 K │ train │
│ 56  │ cfm_net.egnn.gcl_0.node_mlp          │ Sequential    │ 49.4 K │ train │
│ 57  │ cfm_net.egnn.gcl_0.node_mlp.0        │ Linear        │ 32.9 K │ train │
│ 58  │ cfm_net.egnn.gcl_0.node_mlp.2        │ Linear        │ 16.5 K │ train │
│ 59  │ cfm_net.egnn.gcl_0.coord_mlp         │ Sequential    │ 16.6 K │ train │
│ 60  │ cfm_net.egnn.gcl_0.coord_mlp.0       │ Linear        │ 16.5 K │ train │
│ 61  │ cfm_net.egnn.gcl_0.coord_mlp.2       │ Linear        │    128 │ train │
│ 62  │ cfm_net.egnn.gcl_0.coord_mlp.3       │ Tanh          │      0 │ train │
│ 63  │ cfm_net.egnn.gcl_0.att_mlp           │ Sequential    │    129 │ train │
│ 64  │ cfm_net.egnn.gcl_0.att_mlp.0         │ Linear        │    129 │ train │
│ 65  │ cfm_net.egnn.gcl_0.att_mlp.1         │ Sigmoid       │      0 │ train │
│ 66  │ cfm_net.egnn.gcl_1                   │ E_GCL         │  115 K │ train │
│ 67  │ cfm_net.egnn.gcl_1.edge_mlp          │ Sequential    │ 49.7 K │ train │
│ 68  │ cfm_net.egnn.gcl_1.edge_mlp.0        │ Linear        │ 33.2 K │ train │
│ 69  │ cfm_net.egnn.gcl_1.edge_mlp.2        │ Linear        │ 16.5 K │ train │
│ 70  │ cfm_net.egnn.gcl_1.node_mlp          │ Sequential    │ 49.4 K │ train │
│ 71  │ cfm_net.egnn.gcl_1.node_mlp.0        │ Linear        │ 32.9 K │ train │
│ 72  │ cfm_net.egnn.gcl_1.node_mlp.2        │ Linear        │ 16.5 K │ train │
│ 73  │ cfm_net.egnn.gcl_1.coord_mlp         │ Sequential    │ 16.6 K │ train │
│ 74  │ cfm_net.egnn.gcl_1.coord_mlp.0       │ Linear        │ 16.5 K │ train │
│ 75  │ cfm_net.egnn.gcl_1.coord_mlp.2       │ Linear        │    128 │ train │
│ 76  │ cfm_net.egnn.gcl_1.coord_mlp.3       │ Tanh          │      0 │ train │
│ 77  │ cfm_net.egnn.gcl_1.att_mlp           │ Sequential    │    129 │ train │
│ 78  │ cfm_net.egnn.gcl_1.att_mlp.0         │ Linear        │    129 │ train │
│ 79  │ cfm_net.egnn.gcl_1.att_mlp.1         │ Sigmoid       │      0 │ train │
│ 80  │ cfm_net.egnn.gcl_2                   │ E_GCL         │  115 K │ train │
│ 81  │ cfm_net.egnn.gcl_2.edge_mlp          │ Sequential    │ 49.7 K │ train │
│ 82  │ cfm_net.egnn.gcl_2.edge_mlp.0        │ Linear        │ 33.2 K │ train │
│ 83  │ cfm_net.egnn.gcl_2.edge_mlp.2        │ Linear        │ 16.5 K │ train │
│ 84  │ cfm_net.egnn.gcl_2.node_mlp          │ Sequential    │ 49.4 K │ train │
│ 85  │ cfm_net.egnn.gcl_2.node_mlp.0        │ Linear        │ 32.9 K │ train │
│ 86  │ cfm_net.egnn.gcl_2.node_mlp.2        │ Linear        │ 16.5 K │ train │
│ 87  │ cfm_net.egnn.gcl_2.coord_mlp         │ Sequential    │ 16.6 K │ train │
│ 88  │ cfm_net.egnn.gcl_2.coord_mlp.0       │ Linear        │ 16.5 K │ train │
│ 89  │ cfm_net.egnn.gcl_2.coord_mlp.2       │ Linear        │    128 │ train │
│ 90  │ cfm_net.egnn.gcl_2.coord_mlp.3       │ Tanh          │      0 │ train │
│ 91  │ cfm_net.egnn.gcl_2.att_mlp           │ Sequential    │    129 │ train │
│ 92  │ cfm_net.egnn.gcl_2.att_mlp.0         │ Linear        │    129 │ train │
│ 93  │ cfm_net.egnn.gcl_2.att_mlp.1         │ Sigmoid       │      0 │ train │
│ 94  │ cfm_net.egnn.gcl_3                   │ E_GCL         │  115 K │ train │
│ 95  │ cfm_net.egnn.gcl_3.edge_mlp          │ Sequential    │ 49.7 K │ train │
│ 96  │ cfm_net.egnn.gcl_3.edge_mlp.0        │ Linear        │ 33.2 K │ train │
│ 97  │ cfm_net.egnn.gcl_3.edge_mlp.2        │ Linear        │ 16.5 K │ train │
│ 98  │ cfm_net.egnn.gcl_3.node_mlp          │ Sequential    │ 49.4 K │ train │
│ 99  │ cfm_net.egnn.gcl_3.node_mlp.0        │ Linear        │ 32.9 K │ train │
│ 100 │ cfm_net.egnn.gcl_3.node_mlp.2        │ Linear        │ 16.5 K │ train │
│ 101 │ cfm_net.egnn.gcl_3.coord_mlp         │ Sequential    │ 16.6 K │ train │
│ 102 │ cfm_net.egnn.gcl_3.coord_mlp.0       │ Linear        │ 16.5 K │ train │
│ 103 │ cfm_net.egnn.gcl_3.coord_mlp.2       │ Linear        │    128 │ train │
│ 104 │ cfm_net.egnn.gcl_3.coord_mlp.3       │ Tanh          │      0 │ train │
│ 105 │ cfm_net.egnn.gcl_3.att_mlp           │ Sequential    │    129 │ train │
│ 106 │ cfm_net.egnn.gcl_3.att_mlp.0         │ Linear        │    129 │ train │
│ 107 │ cfm_net.egnn.gcl_3.att_mlp.1         │ Sigmoid       │      0 │ train │
│ 108 │ cfm_net.egnn.gcl_4                   │ E_GCL         │  115 K │ train │
│ 109 │ cfm_net.egnn.gcl_4.edge_mlp          │ Sequential    │ 49.7 K │ train │
│ 110 │ cfm_net.egnn.gcl_4.edge_mlp.0        │ Linear        │ 33.2 K │ train │
│ 111 │ cfm_net.egnn.gcl_4.edge_mlp.2        │ Linear        │ 16.5 K │ train │
│ 112 │ cfm_net.egnn.gcl_4.node_mlp          │ Sequential    │ 49.4 K │ train │
│ 113 │ cfm_net.egnn.gcl_4.node_mlp.0        │ Linear        │ 32.9 K │ train │
│ 114 │ cfm_net.egnn.gcl_4.node_mlp.2        │ Linear        │ 16.5 K │ train │
│ 115 │ cfm_net.egnn.gcl_4.coord_mlp         │ Sequential    │ 16.6 K │ train │
│ 116 │ cfm_net.egnn.gcl_4.coord_mlp.0       │ Linear        │ 16.5 K │ train │
│ 117 │ cfm_net.egnn.gcl_4.coord_mlp.2       │ Linear        │    128 │ train │
│ 118 │ cfm_net.egnn.gcl_4.coord_mlp.3       │ Tanh          │      0 │ train │
│ 119 │ cfm_net.egnn.gcl_4.att_mlp           │ Sequential    │    129 │ train │
│ 120 │ cfm_net.egnn.gcl_4.att_mlp.0         │ Linear        │    129 │ train │
│ 121 │ cfm_net.egnn.gcl_4.att_mlp.1         │ Sigmoid       │      0 │ train │
│ 122 │ net                                  │ EnergyModel   │  579 K │ train │
│ 123 │ net.score_net                        │ EGNN_dynamics │  579 K │ train │
│ 124 │ net.score_net.egnn                   │ EGNN          │  579 K │ train │
│ 125 │ net.score_net.egnn.embedding         │ Linear        │    256 │ train │
│ 126 │ net.score_net.egnn.embedding_out     │ Linear        │    129 │ train │
│ 127 │ net.score_net.egnn.gcl_0             │ E_GCL         │  115 K │ train │
│ 128 │ net.score_net.egnn.gcl_0.edge_mlp    │ Sequential    │ 49.7 K │ train │
│ 129 │ net.score_net.egnn.gcl_0.edge_mlp.0  │ Linear        │ 33.2 K │ train │
│ 130 │ net.score_net.egnn.gcl_0.edge_mlp.2  │ Linear        │ 16.5 K │ train │
│ 131 │ net.score_net.egnn.gcl_0.node_mlp    │ Sequential    │ 49.4 K │ train │
│ 132 │ net.score_net.egnn.gcl_0.node_mlp.0  │ Linear        │ 32.9 K │ train │
│ 133 │ net.score_net.egnn.gcl_0.node_mlp.2  │ Linear        │ 16.5 K │ train │
│ 134 │ net.score_net.egnn.gcl_0.coord_mlp   │ Sequential    │ 16.6 K │ train │
│ 135 │ net.score_net.egnn.gcl_0.coord_mlp.0 │ Linear        │ 16.5 K │ train │
│ 136 │ net.score_net.egnn.gcl_0.coord_mlp.2 │ Linear        │    128 │ train │
│ 137 │ net.score_net.egnn.gcl_0.coord_mlp.3 │ Tanh          │      0 │ train │
│ 138 │ net.score_net.egnn.gcl_0.att_mlp     │ Sequential    │    129 │ train │
│ 139 │ net.score_net.egnn.gcl_0.att_mlp.0   │ Linear        │    129 │ train │
│ 140 │ net.score_net.egnn.gcl_0.att_mlp.1   │ Sigmoid       │      0 │ train │
│ 141 │ net.score_net.egnn.gcl_1             │ E_GCL         │  115 K │ train │
│ 142 │ net.score_net.egnn.gcl_1.edge_mlp    │ Sequential    │ 49.7 K │ train │
│ 143 │ net.score_net.egnn.gcl_1.edge_mlp.0  │ Linear        │ 33.2 K │ train │
│ 144 │ net.score_net.egnn.gcl_1.edge_mlp.2  │ Linear        │ 16.5 K │ train │
│ 145 │ net.score_net.egnn.gcl_1.node_mlp    │ Sequential    │ 49.4 K │ train │
│ 146 │ net.score_net.egnn.gcl_1.node_mlp.0  │ Linear        │ 32.9 K │ train │
│ 147 │ net.score_net.egnn.gcl_1.node_mlp.2  │ Linear        │ 16.5 K │ train │
│ 148 │ net.score_net.egnn.gcl_1.coord_mlp   │ Sequential    │ 16.6 K │ train │
│ 149 │ net.score_net.egnn.gcl_1.coord_mlp.0 │ Linear        │ 16.5 K │ train │
│ 150 │ net.score_net.egnn.gcl_1.coord_mlp.2 │ Linear        │    128 │ train │
│ 151 │ net.score_net.egnn.gcl_1.coord_mlp.3 │ Tanh          │      0 │ train │
│ 152 │ net.score_net.egnn.gcl_1.att_mlp     │ Sequential    │    129 │ train │
│ 153 │ net.score_net.egnn.gcl_1.att_mlp.0   │ Linear        │    129 │ train │
│ 154 │ net.score_net.egnn.gcl_1.att_mlp.1   │ Sigmoid       │      0 │ train │
│ 155 │ net.score_net.egnn.gcl_2             │ E_GCL         │  115 K │ train │
│ 156 │ net.score_net.egnn.gcl_2.edge_mlp    │ Sequential    │ 49.7 K │ train │
│ 157 │ net.score_net.egnn.gcl_2.edge_mlp.0  │ Linear        │ 33.2 K │ train │
│ 158 │ net.score_net.egnn.gcl_2.edge_mlp.2  │ Linear        │ 16.5 K │ train │
│ 159 │ net.score_net.egnn.gcl_2.node_mlp    │ Sequential    │ 49.4 K │ train │
│ 160 │ net.score_net.egnn.gcl_2.node_mlp.0  │ Linear        │ 32.9 K │ train │
│ 161 │ net.score_net.egnn.gcl_2.node_mlp.2  │ Linear        │ 16.5 K │ train │
│ 162 │ net.score_net.egnn.gcl_2.coord_mlp   │ Sequential    │ 16.6 K │ train │
│ 163 │ net.score_net.egnn.gcl_2.coord_mlp.0 │ Linear        │ 16.5 K │ train │
│ 164 │ net.score_net.egnn.gcl_2.coord_mlp.2 │ Linear        │    128 │ train │
│ 165 │ net.score_net.egnn.gcl_2.coord_mlp.3 │ Tanh          │      0 │ train │
│ 166 │ net.score_net.egnn.gcl_2.att_mlp     │ Sequential    │    129 │ train │
│ 167 │ net.score_net.egnn.gcl_2.att_mlp.0   │ Linear        │    129 │ train │
│ 168 │ net.score_net.egnn.gcl_2.att_mlp.1   │ Sigmoid       │      0 │ train │
│ 169 │ net.score_net.egnn.gcl_3             │ E_GCL         │  115 K │ train │
│ 170 │ net.score_net.egnn.gcl_3.edge_mlp    │ Sequential    │ 49.7 K │ train │
│ 171 │ net.score_net.egnn.gcl_3.edge_mlp.0  │ Linear        │ 33.2 K │ train │
│ 172 │ net.score_net.egnn.gcl_3.edge_mlp.2  │ Linear        │ 16.5 K │ train │
│ 173 │ net.score_net.egnn.gcl_3.node_mlp    │ Sequential    │ 49.4 K │ train │
│ 174 │ net.score_net.egnn.gcl_3.node_mlp.0  │ Linear        │ 32.9 K │ train │
│ 175 │ net.score_net.egnn.gcl_3.node_mlp.2  │ Linear        │ 16.5 K │ train │
│ 176 │ net.score_net.egnn.gcl_3.coord_mlp   │ Sequential    │ 16.6 K │ train │
│ 177 │ net.score_net.egnn.gcl_3.coord_mlp.0 │ Linear        │ 16.5 K │ train │
│ 178 │ net.score_net.egnn.gcl_3.coord_mlp.2 │ Linear        │    128 │ train │
│ 179 │ net.score_net.egnn.gcl_3.coord_mlp.3 │ Tanh          │      0 │ train │
│ 180 │ net.score_net.egnn.gcl_3.att_mlp     │ Sequential    │    129 │ train │
│ 181 │ net.score_net.egnn.gcl_3.att_mlp.0   │ Linear        │    129 │ train │
│ 182 │ net.score_net.egnn.gcl_3.att_mlp.1   │ Sigmoid       │      0 │ train │
│ 183 │ net.score_net.egnn.gcl_4             │ E_GCL         │  115 K │ train │
│ 184 │ net.score_net.egnn.gcl_4.edge_mlp    │ Sequential    │ 49.7 K │ train │
│ 185 │ net.score_net.egnn.gcl_4.edge_mlp.0  │ Linear        │ 33.2 K │ train │
│ 186 │ net.score_net.egnn.gcl_4.edge_mlp.2  │ Linear        │ 16.5 K │ train │
│ 187 │ net.score_net.egnn.gcl_4.node_mlp    │ Sequential    │ 49.4 K │ train │
│ 188 │ net.score_net.egnn.gcl_4.node_mlp.0  │ Linear        │ 32.9 K │ train │
│ 189 │ net.score_net.egnn.gcl_4.node_mlp.2  │ Linear        │ 16.5 K │ train │
│ 190 │ net.score_net.egnn.gcl_4.coord_mlp   │ Sequential    │ 16.6 K │ train │
│ 191 │ net.score_net.egnn.gcl_4.coord_mlp.0 │ Linear        │ 16.5 K │ train │
│ 192 │ net.score_net.egnn.gcl_4.coord_mlp.2 │ Linear        │    128 │ train │
│ 193 │ net.score_net.egnn.gcl_4.coord_mlp.3 │ Tanh          │      0 │ train │
│ 194 │ net.score_net.egnn.gcl_4.att_mlp     │ Sequential    │    129 │ train │
│ 195 │ net.score_net.egnn.gcl_4.att_mlp.0   │ Linear        │    129 │ train │
│ 196 │ net.score_net.egnn.gcl_4.att_mlp.1   │ Sigmoid       │      0 │ train │
│ 197 │ reverse_sde                          │ VEReverseSDE  │  579 K │ train │
│ 198 │ dem_cnf                              │ CNF           │  579 K │ train │
│ 199 │ cfm_cnf                              │ CNF           │  579 K │ train │
└─────┴──────────────────────────────────────┴───────────────┴────────┴───────┘
Trainable params: 1.2 M                                                         
Non-trainable params: 0                                                         
Total params: 1.2 M                                                             
Total estimated model params size (MB): 4                                       
Modules in train mode: 200                                                      
Modules in eval mode: 0                                                         
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=5` in the `DataLoader` to improve performance.
/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/numpy/lib/histograms.py:885: RuntimeWarning: invalid value encountered in divide
  return n/db/n.sum(), bin_edges
Metric val/energy_w2 improved. New best score: 96125.398
/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py:590: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  idx = torch.randint(0, logweights.shape[1], (15,))
Metric val/energy_w2 improved by 13888.445 >= min_delta = 0.0. New best score: 82236.953
Metric val/energy_w2 improved by 12188.906 >= min_delta = 0.0. New best score: 70048.047
Metric val/energy_w2 improved by 33616.547 >= min_delta = 0.0. New best score: 36431.500
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [0,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [1,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [2,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [3,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [4,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [5,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [6,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [7,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [8,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [9,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [10,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [11,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [12,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [13,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [14,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [15,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [16,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [17,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [18,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [19,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [20,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [21,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [22,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [23,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [24,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [25,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [26,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [27,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [28,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [29,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [30,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
/opt/conda/conda-bld/pytorch_1720538438429/work/aten/src/ATen/native/cuda/MultinomialKernel.cu:112: binarySearchForMultinomial: block: [0,0,0], thread: [31,0,0] Assertion `cumdist[size - 1] > static_cast<scalar_t>(0)` failed.
Epoch 90/1999 ━━━━━━━━━━━━━━━ 100/100 0:00:36 •       2.72it/s v_num: 4vjl      
                                      0:00:00                  train/dem_loss:  
                                                               958.344          
                                                               val/energy_w2:   
                                                               4993316875805301…
                                                               val/dist_w2:     
                                                               180.992          
                                                               val/dist_total_v…
                                                               0.668            
                                                               val/loss_step:   
                                                               74.256           
                                                               val/loss_epoch:  
                                                               58.792           
[[36m2024-11-02 14:29:12,173[0m][[34msrc.utils.utils[0m][[31mERROR[0m] - [rank: 0] [0m
Traceback (most recent call last):
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 206, in run
    self.on_advance_end()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 377, in on_advance_end
    call._call_lightning_module_hook(trainer, "on_train_epoch_end")
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 568, in on_train_epoch_end
    return_logweights=True
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 499, in generate_samples
    samples, logweights = self.integrate(
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 524, in integrate
    trajectory, logweights = integrate_sde(
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sde_integration.py", line 149, in integrate_sde
    x, a, a_plot = euler_maruyama_step(sde, t, x, a,
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sde_integration.py", line 32, in euler_maruyama_step
    drift_Xt, drift_At = sde.f(t, x, resampling_interval)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sdes.py", line 38, in f
    t = t * torch.ones(x.shape[0]).to(x.device)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/utils/utils.py", line 68, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/train.py", line 106, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 68, in _call_and_handle_interrupt
    trainer._teardown()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1004, in _teardown
    self.strategy.teardown()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 531, in teardown
    _optimizers_to_device(self.optimizers, torch.device("cpu"))
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 28, in _optimizers_to_device
    _optimizer_to_device(opt, device)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 42, in _optimizer_to_device
    v[key] = move_data_to_device(val, device)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 110, in move_data_to_device
    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 104, in batch_to
    data_output = data.to(device, **kwargs)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[[36m2024-11-02 14:29:12,200[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiruns/2024-11-02_09-56-25/0[0m
[[36m2024-11-02 14:29:12,200[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: - 1.653 MB of 1.653 MB uploadedwandb: \ 1.653 MB of 1.653 MB uploadedwandb: | 1.653 MB of 1.653 MB uploadedwandb: / 1.685 MB of 1.727 MB uploaded (0.004 MB deduped)wandb: - 1.685 MB of 1.727 MB uploaded (0.004 MB deduped)wandb: \ 1.727 MB of 1.727 MB uploaded (0.004 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                                   epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                          train/dem_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb: train/stratified/dem_loss t=[0.00,0.20) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb: train/stratified/dem_loss t=[0.20,0.40) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb: train/stratified/dem_loss t=[0.40,0.60) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁█
wandb: train/stratified/dem_loss t=[0.60,0.80) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb: train/stratified/dem_loss t=[0.80,1.00) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:                     trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▁▆▆▆▆▇▇▇▇▇▇███
wandb:                       val/1-Wasserstein █▁▁▁▁
wandb:                       val/2-Wasserstein █▁▁▁▁
wandb:                             val/Eq-EMD2 █▁▁▁▁
wandb:                          val/Linear_MMD █▁▁▁▁
wandb:                             val/Mean_L1 █▃▂▁▁
wandb:                             val/Mean_L2 █▃▂▁▁
wandb:                            val/Mean_MSE █▂▂▁▁
wandb:                           val/Median_L1 █▂▂▁▁
wandb:                           val/Median_L2 █▂▂▁▁
wandb:                          val/Median_MSE █▂▂▁▁
wandb:                            val/Poly_MMD █▁▁▁▁
wandb:                             val/RBF_MMD ▁▇▇▇█
wandb:                      val/dist_total_var ▅▂▄▃▁▃▃▂▃▂▂▄▂▁▂▃▃▃▃▁▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂█
wandb:                             val/dist_w2 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█
wandb:                           val/energy_w2 █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                          val/loss_epoch ▁▄▄▁█
wandb:                           val/loss_step ▃▅▃▂▁▄█▄▄▅▃▅▃▃▄▃▅▆▂█
wandb: 
wandb: Run summary:
wandb:                                   epoch 90
wandb:                          train/dem_loss 3130.96094
wandb: train/stratified/dem_loss t=[0.00,0.20) 83.4585
wandb: train/stratified/dem_loss t=[0.20,0.40) 54.93658
wandb: train/stratified/dem_loss t=[0.40,0.60) 22.91642
wandb: train/stratified/dem_loss t=[0.60,0.80) 18.16203
wandb: train/stratified/dem_loss t=[0.80,1.00) 20.64707
wandb:                     trainer/global_step 9099
wandb:                       val/1-Wasserstein 19.27489
wandb:                       val/2-Wasserstein 19.29245
wandb:                             val/Eq-EMD2 5.155
wandb:                          val/Linear_MMD 207.41075
wandb:                             val/Mean_L1 0.95516
wandb:                             val/Mean_L2 1.13558
wandb:                            val/Mean_MSE 1.28955
wandb:                           val/Median_L1 0.96447
wandb:                           val/Median_L2 1.14949
wandb:                          val/Median_MSE 1.32133
wandb:                            val/Poly_MMD 44124.42969
wandb:                             val/RBF_MMD 1.60229
wandb:                      val/dist_total_var 0.66776
wandb:                             val/dist_w2 180.99203
wandb:                           val/energy_w2 4.993316875805302e+33
wandb:                          val/loss_epoch 58.79182
wandb:                           val/loss_step 74.25627
wandb: 
wandb: 🚀 View run desert-star-801 at: https://wandb.ai/openproblems-comp/DEM-2/runs/td6j4vjl
wandb: ️⚡ View job at https://wandb.ai/openproblems-comp/DEM-2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQxODUwNzQ1NA==/version_details/v80
wandb: Synced 5 W&B file(s), 94 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: /network/scratch/t/tara.akhoundsadegh/dem/logs/train/multiruns/2024-11-02_09-56-25/0/wandb/run-20241102_095637-td6j4vjl/logs
Error executing job with overrides: ['experiment=lj55', 'trainer=gpu']
Traceback (most recent call last):
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 206, in run
    self.on_advance_end()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py", line 377, in on_advance_end
    call._call_lightning_module_hook(trainer, "on_train_epoch_end")
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 568, in on_train_epoch_end
    return_logweights=True
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 499, in generate_samples
    samples, logweights = self.integrate(
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/dem_module.py", line 524, in integrate
    trajectory, logweights = integrate_sde(
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sde_integration.py", line 149, in integrate_sde
    x, a, a_plot = euler_maruyama_step(sde, t, x, a,
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sde_integration.py", line 32, in euler_maruyama_step
    drift_Xt, drift_At = sde.f(t, x, resampling_interval)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/models/components/sdes.py", line 38, in f
    t = t * torch.ones(x.shape[0]).to(x.device)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/train.py", line 139, in main
    metric_dict, _ = train(cfg)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/utils/utils.py", line 78, in wrap
    raise ex
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/utils/utils.py", line 68, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/home/mila/t/tara.akhoundsadegh/active_inference/runner/src/train.py", line 106, in train
    trainer.fit(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 68, in _call_and_handle_interrupt
    trainer._teardown()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1004, in _teardown
    self.strategy.teardown()
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py", line 531, in teardown
    _optimizers_to_device(self.optimizers, torch.device("cpu"))
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 28, in _optimizers_to_device
    _optimizer_to_device(opt, device)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/optimizer.py", line 42, in _optimizer_to_device
    v[key] = move_data_to_device(val, device)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 110, in move_data_to_device
    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/network/scratch/t/tara.akhoundsadegh/demenv/lib/python3.10/site-packages/lightning/fabric/utilities/apply_func.py", line 104, in batch_to
    data_output = data.to(device, **kwargs)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.

======== GPU REPORT ========

==============NVSMI LOG==============

Timestamp                                 : Sat Nov  2 14:29:25 2024
Driver Version                            : 535.161.08
CUDA Version                              : 12.2

Attached GPUs                             : 1
GPU 00000000:90:00.0
    Accounting Mode                       : Enabled
    Accounting Mode Buffer Size           : 4000
    Accounted Processes
        Process ID                        : 97349
            GPU Utilization               : 97 %
            Memory Utilization            : 78 %
            Max memory usage              : 30316 MiB
            Time                          : 16370955 ms
            Is Running                    : 0

Sat Nov  2 14:29:25 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:90:00.0 Off |                    0 |
| N/A   45C    P0              72W / 400W |      0MiB / 40960MiB |     31%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
